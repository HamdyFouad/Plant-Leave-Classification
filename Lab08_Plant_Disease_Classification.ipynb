{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Download dataset\n",
        "!pip install -q gdown\n",
        "\n",
        "# plant_leave_diseases_train.zip\n",
        "!gdown https://drive.google.com/uc?id=1MCQ2ldiKZUeVM1rVw1gPlBaX43AJB3R0\n",
        "\n",
        "# plant_leave_diseases_test.zip\n",
        "!gdown https://drive.google.com/uc?id=1yqvfEVeb0IAutxZK83_wUoUWm5apYSF8"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpzlJF1tQfK6",
        "outputId": "2457d83c-639d-46fa-f7a4-cb102d29a688"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1MCQ2ldiKZUeVM1rVw1gPlBaX43AJB3R0\n",
            "From (redirected): https://drive.google.com/uc?id=1MCQ2ldiKZUeVM1rVw1gPlBaX43AJB3R0&confirm=t&uuid=d8601cd9-d37a-44ff-9c3b-21be41f7a80d\n",
            "To: /content/plant_leave_diseases_train.zip\n",
            "100% 682M/682M [00:12<00:00, 55.1MB/s]\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1yqvfEVeb0IAutxZK83_wUoUWm5apYSF8\n",
            "From (redirected): https://drive.google.com/uc?id=1yqvfEVeb0IAutxZK83_wUoUWm5apYSF8&confirm=t&uuid=b1bd5df2-962c-4dc8-90c0-cd42e11bbbb5\n",
            "To: /content/plant_leave_diseases_test.zip\n",
            "100% 170M/170M [00:02<00:00, 76.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzip data\n",
        "with zipfile.ZipFile('plant_leave_diseases_train.zip', 'r') as zip_file:\n",
        "    zip_file.extractall()\n",
        "\n",
        "with zipfile.ZipFile('plant_leave_diseases_test.zip', 'r') as zip_file:\n",
        "    zip_file.extractall()"
      ],
      "metadata": {
        "id": "EQ_5oG9jQmAq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Paths to your folders\n",
        "train_data_dir = 'plant_leave_diseases_train'\n",
        "\n",
        "# Image settings\n",
        "img_size = (256, 256)\n",
        "batch_size = 32\n",
        "\n",
        "# Create a ImageDataGenerator with validation split\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Training data generator\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "eXjzuZ2SRPB6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fca3ee3-4822-474c-843c-63c38bdb2f1c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 34756 images belonging to 38 classes.\n",
            "Found 8673 images belonging to 38 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build CNN model\n",
        "model = Sequential([\n",
        "    Input(shape=(img_size[0], img_size[1], 3)),\n",
        "    Conv2D(32, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(train_generator.num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile and train\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(train_generator, validation_data=val_generator, epochs=5)"
      ],
      "metadata": {
        "id": "dI5xl0DgqUVs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c7cf8b-3bdc-4956-9527-d2138e881282"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 84ms/step - accuracy: 0.4851 - loss: 2.0107 - val_accuracy: 0.7699 - val_loss: 0.7527\n",
            "Epoch 2/5\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 79ms/step - accuracy: 0.8555 - loss: 0.4562 - val_accuracy: 0.8261 - val_loss: 0.5770\n",
            "Epoch 3/5\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 84ms/step - accuracy: 0.9237 - loss: 0.2336 - val_accuracy: 0.8644 - val_loss: 0.4577\n",
            "Epoch 4/5\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 77ms/step - accuracy: 0.9561 - loss: 0.1323 - val_accuracy: 0.8849 - val_loss: 0.4112\n",
            "Epoch 5/5\n",
            "\u001b[1m1087/1087\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 78ms/step - accuracy: 0.9673 - loss: 0.0996 - val_accuracy: 0.8948 - val_loss: 0.4047\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x798132d9d210>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import shutil # Added for file operations\n",
        "\n",
        "# --- Start of new code to reorganize test data --- #\n",
        "original_test_data_dir = 'plant_leave_diseases_test'\n",
        "reorganized_test_data_dir = os.path.join(original_test_data_dir, 'images')\n",
        "\n",
        "# Create the new subdirectory if it doesn't exist\n",
        "if not os.path.exists(reorganized_test_data_dir):\n",
        "    os.makedirs(reorganized_test_data_dir)\n",
        "\n",
        "# Move all image files from the original test directory to the new subdirectory\n",
        "for filename in os.listdir(original_test_data_dir):\n",
        "    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
        "        src_path = os.path.join(original_test_data_dir, filename)\n",
        "        dst_path = os.path.join(reorganized_test_data_dir, filename)\n",
        "        if os.path.isfile(src_path): # Ensure it's a file, not a directory\n",
        "            shutil.move(src_path, dst_path)\n",
        "# --- End of new code to reorganize test data --- #\n",
        "\n",
        "# Prepare test data generator (now pointing to the reorganized directory)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# It's crucial to set shuffle=False for the test generator to maintain order\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    original_test_data_dir, # Use the reorganized directory\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode=None, # No labels for test set\n",
        "    shuffle=False # Important for matching predictions with filenames\n",
        ")\n",
        "\n",
        "# Get filenames and map them to IDs\n",
        "filenames = test_generator.filenames\n",
        "# Extract base filenames without path and extension, then convert to integer IDs\n",
        "image_ids = [int(os.path.splitext(os.path.basename(f))[0]) for f in filenames]\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(test_generator)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get class labels from the training generator\n",
        "class_labels = list(train_generator.class_indices.keys())\n",
        "predicted_class_names = [class_labels[idx] for idx in predicted_classes]\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'id': image_ids,\n",
        "    'class': predicted_class_names\n",
        "})\n",
        "\n",
        "# Sort by ID to ensure consistent output, although the task states order doesn't matter\n",
        "submission_df = submission_df.sort_values(by='id').reset_index(drop=True)\n",
        "\n",
        "# Format 'id' with leading zeros if necessary (e.g., 00001)\n",
        "submission_df['id'] = submission_df['id'].apply(lambda x: f'{x:05d}')\n",
        "\n",
        "# Define submission filename (replace with actual student ID and optional team name)\n",
        "student_id = '12502379' # Replace with your actual student ID\n",
        "team_name = 'Mariam' # Optional: Replace with your team name, e.g., 'MyTeam'\n",
        "\n",
        "if team_name:\n",
        "    submission_filename = f'submission_{student_id}_{team_name}.csv'\n",
        "else:\n",
        "    submission_filename = f'submission_{student_id}.csv'\n",
        "\n",
        "# Save to CSV\n",
        "submission_df.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f'Submission file saved as: {submission_filename}')"
      ],
      "metadata": {
        "id": "jesqdCrs_-7t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60e6cc14-c301-477b-fa60-f8d21a523752"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 10876 images belonging to 1 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m340/340\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 58ms/step\n",
            "Submission file saved as: submission_12502379_Mariam.csv\n"
          ]
        }
      ]
    }
  ]
}